# Ficheiro: src/services/huggingface_client.py

import logging
import requests
from typing import Optional

# Importa a configura√ß√£o centralizada para aceder √† chave de API e nomes de modelos
from config import Config

logger = logging.getLogger(__name__)

class HuggingFaceClient:
    """
    Cliente para interagir com a Hugging Face Inference API.
    Funciona como um fallback robusto para a gera√ß√£o de texto.
    """
    def __init__(self):
        """
        Verifica se a chave de API do Hugging Face est√° dispon√≠vel.
        """
        self.api_key = Config.HUGGINGFACE_API_KEY
        if self.api_key:
            logger.info("‚úÖ Cliente Hugging Face inicializado com sucesso.")
        else:
            logger.warning("‚ö†Ô∏è Chave de API do Hugging Face n√£o foi encontrada. O servi√ßo est√° desativado.")

    def generate_content(self, prompt: str, max_tokens: int = 4096) -> Optional[str]:
        """
        Envia um prompt para um modelo na Hugging Face Inference API.

        Args:
            prompt: O texto de entrada para a IA.
            max_tokens: O n√∫mero m√°ximo de novos tokens a serem gerados.

        Returns:
            A resposta de texto gerada pela IA ou None em caso de falha.
        """
        if not self.api_key:
            logger.error("‚ùå N√£o √© poss√≠vel gerar conte√∫do: a chave da API do Hugging Face n√£o est√° configurada.")
            return None

        # Usa o modelo definido na configura√ß√£o, com um fallback para um modelo popular e gratuito.
        model_name = Config.HUGGINGFACE_MODEL_NAME or "mistralai/Mistral-7B-Instruct-v0.2"
        api_url = f"https://api-inference.huggingface.co/models/{model_name}"
        headers = {"Authorization": f"Bearer {self.api_key}"}

        # Payload para a API
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": max_tokens,
                "temperature": 0.7,
                "top_p": 0.95,
                "return_full_text": False, # Retorna apenas o texto gerado, n√£o o prompt
            }
        }

        logger.info(f"ü§ñ A enviar pedido para a API do Hugging Face (Modelo: {model_name})...")
        try:
            response = requests.post(api_url, headers=headers, json=payload, timeout=90) # Timeout mais longo para modelos maiores

            if response.status_code == 200:
                result = response.json()
                # A resposta √© uma lista, o texto est√° no primeiro elemento
                content = result[0]['generated_text']
                logger.info(f"‚úÖ Resposta recebida com sucesso do Hugging Face.")
                return content.strip()
            elif response.status_code == 503:
                 logger.error(f"‚ùå Erro na API do Hugging Face: Modelo '{model_name}' est√° a carregar. Tente novamente mais tarde.")
                 return None
            else:
                logger.error(f"‚ùå Erro na API do Hugging Face: {response.status_code} - {response.text}")
                return None

        except requests.RequestException as e:
            logger.error(f"‚ùå Ocorreu um erro de rede na chamada √† API do Hugging Face: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Ocorreu um erro inesperado ao processar a resposta do Hugging Face: {e}")
            return None

# --- Inst√¢ncia Global ---
# Cria uma √∫nica inst√¢ncia do HuggingFaceClient para ser usada em toda a aplica√ß√£o.
huggingface_client = HuggingFaceClient()
