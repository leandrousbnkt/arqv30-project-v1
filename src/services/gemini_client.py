# Ficheiro: src/services/gemini_client.py

import logging
import google.generativeai as genai
from typing import Optional

# Importa a configura√ß√£o centralizada para aceder √† chave de API
from config import Config

logger = logging.getLogger(__name__)

class GeminiClient:
    """
    Cliente robusto para interagir com a API do Google Gemini.
    Centraliza a configura√ß√£o e a l√≥gica de gera√ß√£o de conte√∫do.
    """
    def __init__(self):
        """
        Configura o cliente Gemini ao ser inicializado.
        """
        self.model = None
        if Config.GEMINI_API_KEY:
            try:
                genai.configure(api_key=Config.GEMINI_API_KEY)
                # Utiliza o modelo 'gemini-1.5-flash', que √© r√°pido e eficiente para tarefas de texto.
                self.model = genai.GenerativeModel("gemini-1.5-flash")
                logger.info("‚úÖ Cliente Gemini inicializado com sucesso.")
            except Exception as e:
                logger.error(f"‚ùå Falha ao configurar a API do Gemini: {e}")
        else:
            logger.warning("‚ö†Ô∏è Chave de API do Gemini n√£o foi encontrada. O servi√ßo Gemini est√° desativado.")

    def generate_content(self, prompt: str, max_tokens: int = 8192) -> Optional[str]:
        """
        Envia um prompt para o modelo Gemini e retorna a resposta de texto.

        Args:
            prompt: O texto de entrada para a IA.
            max_tokens: O n√∫mero m√°ximo de tokens na resposta.

        Returns:
            A resposta de texto gerada pela IA ou None em caso de falha.
        """
        if not self.model:
            logger.error("‚ùå N√£o √© poss√≠vel gerar conte√∫do: o modelo Gemini n√£o foi inicializado.")
            return None

        try:
            # Configura√ß√µes de gera√ß√£o para obter respostas criativas e detalhadas
            generation_config = {
                'temperature': 0.7,
                'top_p': 0.95,
                'top_k': 64,
                'max_output_tokens': max_tokens,
            }
            
            # Configura√ß√µes de seguran√ßa para evitar bloqueios por conte√∫do sens√≠vel
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            ]

            logger.info("ü§ñ A enviar pedido para a API do Gemini...")
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            if response.text:
                logger.info("‚úÖ Resposta recebida com sucesso do Gemini.")
                return response.text
            else:
                logger.warning(f"‚ö†Ô∏è Gemini retornou uma resposta vazia. Feedback de seguran√ßa: {response.prompt_feedback}")
                return None

        except Exception as e:
            logger.error(f"‚ùå Ocorreu um erro na chamada √† API do Gemini: {e}")
            return None

# --- Inst√¢ncia Global ---
# Cria uma √∫nica inst√¢ncia do GeminiClient para ser usada em toda a aplica√ß√£o.
gemini_client = GeminiClient()
